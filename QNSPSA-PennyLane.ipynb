{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6a4420-64f0-439c-a2a5-a85e99875995",
   "metadata": {},
   "source": [
    "# QNSPSA vs SPSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbfb765-72d5-41ac-8f9f-0b0364a4e877",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d365797-cc17-4f25-b8ed-769d28547426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml \n",
    "from pennylane import numpy as np\n",
    "from sklearn import datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eceec5-77d3-4e78-90ae-b36f4ecbd6fa",
   "metadata": {},
   "source": [
    "## Data Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c7f302-33fd-4ff9-98ed-f04c733a97b3",
   "metadata": {},
   "source": [
    "Data generation using `sklearn` with `1000` samples and `52`features like the German dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53a96cc-f1b3-43df-bc15-c96bd182d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.make_classification(n_samples=1000, n_features=52, n_classes=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded2dad-ce94-4b7f-9867-4811b527048a",
   "metadata": {},
   "source": [
    "## SPSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2903be64-e036-4355-8f7b-50f187d10e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 8 #8\n",
    "dev = qml.device('lightning.qubit', wires = num_qubits, shots=10000) # lightning.qubit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bec161-7960-49a7-9010-1d2e739c3af2",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a59e33f-9f20-4065-b233-f57121186e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitudes(f=None, num_qubits=None):\n",
    "    qml.AmplitudeEmbedding(features=f, pad_with=0.,wires=range(num_qubits),normalize=True)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\") # , interface=\"autograd\"\n",
    "def circuit(weights, x, num_qubits, depth):\n",
    "    '''\n",
    "    Parametrized circuit with data encoding (statepreparation) and layer repetition based on the weights \n",
    "    Args:\n",
    "        weights: angles for the rotations (num layer, num qubits, num directions)\n",
    "        x: input vector\n",
    "    Return: \n",
    "        Expectation values measured on Pauli Z operators for the state 0\n",
    "    '''\n",
    "    # data encoding \n",
    "    amplitudes(x, num_qubits=num_qubits)\n",
    "\n",
    "    # ansatz \n",
    "    #for W in weights:\n",
    "    ansatz_2(weights,num_qubits=num_qubits, depth=depth)\n",
    "\n",
    "    # measure\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier(weights, x, num_qubits, depth, bias):\n",
    "    '''\n",
    "    Build the parametrized circuit with weights, x and bias term\n",
    "    Args:\n",
    "        - weights: rotation angles \n",
    "        - bias: classical term to add more freedom to the VQA\n",
    "        - x: input vector/data \n",
    "    Returns: \n",
    "        - parametrized circuit with a bias term \n",
    "    '''\n",
    "    return circuit(weights, x, num_qubits, depth) + bias\n",
    "\n",
    "def square_loss(labels, predictions):\n",
    "    '''\n",
    "    Compute the cost function\n",
    "    Args:\n",
    "        - labels: Ground truth\n",
    "        - predictions: Predicted values \n",
    "    Returns: \n",
    "        - Mean of the square error between labels and predictions = model's error \n",
    "    '''\n",
    "    \n",
    "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
    "    #print(labels, predictions)\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    '''\n",
    "    Compute the accuracy of the model\n",
    "    Args:\n",
    "        - labels: Ground truth\n",
    "        - predictions: Predicted values \n",
    "    Returns: \n",
    "        - accuracy\n",
    "    '''\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc\n",
    "\n",
    "def cost(weights, num_qubits, depth, bias, X, Y):\n",
    "    '''\n",
    "    Compute the cost of the model\n",
    "    Args: \n",
    "        - weights: rotation angles \n",
    "        - bias: classical term to add more freedom to the VQA\n",
    "        - X: input vector/data \n",
    "        - Y: True labels \n",
    "    Returns: \n",
    "        - Error prediction / distance \n",
    "    '''\n",
    "    \n",
    "    predictions = [variational_classifier(weights, x, num_qubits, depth, bias)._value.tolist() for x in X]\n",
    "    #print(predictions)\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "def cost2(weights, num_qubits, depth, bias, X, Y):\n",
    "    '''\n",
    "    Compute the cost of the model\n",
    "    Args: \n",
    "        - weights: rotation angles \n",
    "        - bias: classical term to add more freedom to the VQA\n",
    "        - X: input vector/data \n",
    "        - Y: True labels \n",
    "    Returns: \n",
    "        - Error prediction / distance \n",
    "    '''\n",
    "    \n",
    "    predictions = [variational_classifier(weights, x, num_qubits, depth, bias) for x in X]\n",
    "    #print(predictions)\n",
    "    return square_loss(Y, predictions)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def ansatz_2(theta:list, num_qubits=10, depth=1):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    step = 0\n",
    "    for _ in range(depth):\n",
    "        for i in range(num_qubits):\n",
    "            qml.RY(theta[i+step], wires=i)\n",
    "        for i in range(num_qubits-1):\n",
    "            qml.CNOT([i,i+1])\n",
    "        for i in range(num_qubits):\n",
    "            qml.RY(theta[i+step], wires=i)\n",
    "        step += num_qubits\n",
    "        \n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ca6c56-eff4-4144-bfd6-2263cf9676b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_init = 0.01 * np.random.randn(4*num_qubits, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23bdfcf-1848-4ae6-bd2c-bf21207d02eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 1.8052472 | Accuracy: 0.5010000 \n",
      "Iter:     2 | Cost: 1.6553679 | Accuracy: 0.5010000 \n",
      "Iter:     4 | Cost: 1.6497406 | Accuracy: 0.5010000 \n",
      "Iter:     5 | Cost: 1.5357549 | Accuracy: 0.5010000 \n",
      "Iter:     6 | Cost: 1.4926960 | Accuracy: 0.5010000 \n",
      "Iter:     7 | Cost: 1.4625214 | Accuracy: 0.5010000 \n",
      "Iter:     8 | Cost: 1.3857168 | Accuracy: 0.5010000 \n",
      "Iter:    12 | Cost: 1.3751447 | Accuracy: 0.5010000 \n",
      "Iter:    13 | Cost: 1.3546881 | Accuracy: 0.5010000 \n",
      "Iter:    14 | Cost: 1.2847192 | Accuracy: 0.5010000 \n",
      "Iter:    15 | Cost: 1.2576655 | Accuracy: 0.5010000 \n",
      "Iter:    16 | Cost: 1.2058155 | Accuracy: 0.5010000 \n",
      "Iter:    17 | Cost: 1.2012717 | Accuracy: 0.5010000 \n",
      "Iter:    18 | Cost: 1.1908020 | Accuracy: 0.5010000 \n",
      "Iter:    19 | Cost: 1.1639871 | Accuracy: 0.5010000 \n",
      "Iter:    20 | Cost: 1.1411140 | Accuracy: 0.5010000 \n",
      "Iter:    21 | Cost: 1.1040472 | Accuracy: 0.5010000 \n",
      "Iter:    23 | Cost: 1.0821143 | Accuracy: 0.5010000 \n",
      "Iter:    29 | Cost: 1.0719000 | Accuracy: 0.5010000 \n",
      "Iter:    30 | Cost: 1.0509428 | Accuracy: 0.5010000 \n",
      "Iter:    31 | Cost: 1.0500803 | Accuracy: 0.5010000 \n",
      "Iter:    32 | Cost: 1.0493187 | Accuracy: 0.5010000 \n",
      "Iter:    33 | Cost: 1.0434607 | Accuracy: 0.5010000 \n",
      "Iter:    34 | Cost: 1.0420441 | Accuracy: 0.5010000 \n",
      "Iter:    35 | Cost: 1.0326051 | Accuracy: 0.5010000 \n",
      "Iter:    40 | Cost: 1.0291764 | Accuracy: 0.5010000 \n",
      "Iter:    41 | Cost: 1.0263568 | Accuracy: 0.5010000 \n",
      "Iter:    44 | Cost: 1.0238710 | Accuracy: 0.5010000 \n",
      "Iter:    45 | Cost: 1.0233718 | Accuracy: 0.5010000 \n",
      "Iter:    47 | Cost: 1.0110676 | Accuracy: 0.5010000 \n",
      "Iter:    48 | Cost: 1.0062296 | Accuracy: 0.5010000 \n",
      "Iter:    49 | Cost: 1.0056866 | Accuracy: 0.5010000 \n",
      "Iter:    55 | Cost: 1.0042689 | Accuracy: 0.5010000 \n",
      "Iter:    56 | Cost: 1.0026389 | Accuracy: 0.5010000 \n",
      "Iter:    66 | Cost: 1.0022248 | Accuracy: 0.5010000 \n"
     ]
    }
   ],
   "source": [
    "opt = qml.SPSAOptimizer(250)\n",
    "#opt = qml.NesterovMomentumOptimizer(0.5)\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "X_ = data[0]#np.concatenate([X_new, X_transform.to_numpy()], axis=1) #data_res.to_numpy() X_new\n",
    "Y_ = data[1] #y\n",
    "Y_ = Y_ * 2 - 1\n",
    "depth = 2\n",
    "batch_size = 5*depth #5\n",
    "num_qubits = 8 #8\n",
    "cost_saved = []\n",
    "_cost_ref_ = 10 \n",
    "for it in range(250):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X_), (batch_size,))\n",
    "    X_batch = X_[batch_index]\n",
    "    Y_batch = Y_[batch_index]\n",
    "    \n",
    "    weights, _, _, bias,_,_ = opt.step(cost2, weights, num_qubits, 2, bias, X_batch, Y_batch)\n",
    "    #weights, _, _, bias,_,_ = opt.step_and_cost(circuit, X_batch, weights, num_qubits, 1)\n",
    "    \n",
    "    #params, loss = opt.step(cost2, weights, num_qubits, 1, bias, X_batch, Y_batch)\n",
    "    #print(np.sign(variational_classifier(weights, X_batch[0], num_qubits, depth, bias)))\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, x, num_qubits, 2, bias)) for x in X_]\n",
    "    #print(list(zip(Y_ , predictions)))\n",
    "    acc = accuracy(Y_, predictions)\n",
    "    _cost_ = cost2(weights, num_qubits, 2, bias, X_, Y_)\n",
    "    cost_saved.append(_cost_)\n",
    "    if _cost_ref_ > _cost_:\n",
    "        print(\n",
    "            \"Iter: {:5d} | Cost: {:0.7f} | Accuracy: {:0.7f} \".format(\n",
    "                it + 1, cost_saved[-1], acc\n",
    "            )\n",
    "        )\n",
    "        _cost_ref_ = _cost_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142b613-51f5-4ab1-9e7c-cc3a6839a53e",
   "metadata": {},
   "source": [
    "# QNSPSA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e23fe-0bbb-48fb-a329-f4a55565b314",
   "metadata": {},
   "source": [
    "Now, the `SPSA` is working. We can test with `QNSPSA` which is a different optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3de2550e-e9f7-4059-94e6-274209ccc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = qml.QNSPSAOptimizer(stepsize=5e-2)\n",
    "dev = qml.device(\"lightning.qubit\", wires=num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0191ee-c96c-43a8-976a-fd8ab76a9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)#, interface=\"autograd\") # , interface=\"autograd\"\n",
    "def circuit(parameters):\n",
    "    '''\n",
    "    Parametrized circuit with data encoding (statepreparation) and layer repetition based on the weights \n",
    "    Args:\n",
    "        weights: angles for the rotations (num layer, num qubits, num directions)\n",
    "        x: input vector\n",
    "    Return: \n",
    "        Expectation values measured on Pauli Z operators for the state 0\n",
    "    '''\n",
    "    # data encoding \n",
    "    amplitudes(parameters[1], num_qubits=parameters[2])\n",
    "\n",
    "    # ansatz \n",
    "    #for W in weights:\n",
    "    ansatz_2(parameters[0],num_qubits=parameters[2], depth=parameters[3])\n",
    "\n",
    "    # measure\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be32c92-6fc2-441e-a687-765bf21d49bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m Y_[batch_index]\n\u001b[1;32m     25\u001b[0m params \u001b[38;5;241m=\u001b[39m (weights, X_batch, num_qubits, depth)\n\u001b[0;32m---> 26\u001b[0m params, loss \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: cost = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PinQ2_py/lib/python3.9/site-packages/pennylane/optimize/qnspsa.py:185\u001b[0m, in \u001b[0;36mQNSPSAOptimizer.step_and_cost\u001b[0;34m(self, cost, *args, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_and_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, cost, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Update trainable parameters with one step of the optimizer and return\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m    the corresponding objective function value after the step.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m        function output prior to the step\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     params_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocking:\n\u001b[1;32m    188\u001b[0m         loss_curr \u001b[38;5;241m=\u001b[39m cost(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/PinQ2_py/lib/python3.9/site-packages/pennylane/optimize/qnspsa.py:215\u001b[0m, in \u001b[0;36mQNSPSAOptimizer._step_core\u001b[0;34m(self, cost, args, kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m grad_tapes, grad_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_spsa_grad_tapes(cost, args, kwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m# metric_tapes contains 4 tapes for tensor estimation\u001b[39;00m\n\u001b[0;32m--> 215\u001b[0m metric_tapes, tensor_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tensor_tapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m all_grad_tapes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m grad_tapes\n\u001b[1;32m    217\u001b[0m all_metric_tapes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m metric_tapes\n",
      "File \u001b[0;32m~/PinQ2_py/lib/python3.9/site-packages/pennylane/optimize/qnspsa.py:408\u001b[0m, in \u001b[0;36mQNSPSAOptimizer._get_tensor_tapes\u001b[0;34m(self, cost, args, kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     args_list[\u001b[38;5;241m2\u001b[39m][index] \u001b[38;5;241m=\u001b[39m arg \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinite_diff_step \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39mdir1 \u001b[38;5;241m+\u001b[39m dir2)\n\u001b[1;32m    407\u001b[0m     args_list[\u001b[38;5;241m3\u001b[39m][index] \u001b[38;5;241m=\u001b[39m arg \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinite_diff_step \u001b[38;5;241m*\u001b[39m dir1\n\u001b[0;32m--> 408\u001b[0m dir_vecs \u001b[38;5;241m=\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir1_list\u001b[49m\u001b[43m)\u001b[49m, np\u001b[38;5;241m.\u001b[39mconcatenate(dir2_list))\n\u001b[1;32m    409\u001b[0m tapes \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_overlap_tape(cost, args, args_finite_diff, kwargs)\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m args_finite_diff \u001b[38;5;129;01min\u001b[39;00m args_list\n\u001b[1;32m    412\u001b[0m ]\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tapes, dir_vecs\n",
      "File \u001b[0;32m~/PinQ2_py/lib/python3.9/site-packages/pennylane/numpy/wrapper.py:117\u001b[0m, in \u001b[0;36mtensor_wrapper.<locals>._wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         tensor_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _np\u001b[38;5;241m.\u001b[39many([i\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tensor_args])\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# evaluate the original object\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, _np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# only if the output of the object is a ndarray,\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# then convert to a PennyLane tensor\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     res \u001b[38;5;241m=\u001b[39m tensor(res, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtensor_kwargs)\n",
      "File \u001b[0;32m~/PinQ2_py/lib/python3.9/site-packages/autograd/numpy/numpy_wrapper.py:38\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(arr_list, axis)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@primitive\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_args\u001b[39m(axis, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _np\u001b[38;5;241m.\u001b[39mconcatenate(args, axis)\u001b[38;5;241m.\u001b[39mview(ndarray)\n\u001b[0;32m---> 38\u001b[0m concatenate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m arr_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m : \u001b[43mconcatenate_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marr_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m vstack \u001b[38;5;241m=\u001b[39m row_stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m tup: concatenate([atleast_2d(_m) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m tup], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhstack\u001b[39m(tup):\n",
      "File \u001b[0;32m~/PinQ2_py/lib/python3.9/site-packages/autograd/tracer.py:48\u001b[0m, in \u001b[0;36mprimitive.<locals>.f_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_box(ans, trace, node)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PinQ2_py/lib/python3.9/site-packages/autograd/numpy/numpy_wrapper.py:37\u001b[0m, in \u001b[0;36mconcatenate_args\u001b[0;34m(axis, *args)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@primitive\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_args\u001b[39m(axis, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_np\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(ndarray)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "X_ = data[0] #data_result.to_numpy() # np.concatenate([X_new, X_transform.to_numpy()], axis=1) #data_res.to_numpy() X_new\n",
    "Y_ = data[1] #y\n",
    "Y_ = Y_ * 2 - 1 #2 - 3\n",
    "\n",
    "\n",
    "depth = 1\n",
    "batch_size = 5*depth #5\n",
    "\n",
    "\n",
    "weights_init = 0.01 * np.random.randn(2*depth*num_qubits, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "weights = weights_init\n",
    "bias = bias_init\n",
    "\n",
    "num_qubits = 8 #8\n",
    "cost_saved = []\n",
    "for it in range(100):\n",
    "\n",
    "    # Update the weights by one optimizer step\n",
    "    batch_index = np.random.randint(0, len(X_), (batch_size,))\n",
    "    X_batch = X_[batch_index]\n",
    "    Y_batch = Y_[batch_index]\n",
    "    \n",
    "    params = (weights, X_batch, num_qubits, depth)\n",
    "    params, loss = opt.step_and_cost(circuit, params)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Step {i}: cost = {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a83b48-47e1-49fb-808c-59675668f471",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
